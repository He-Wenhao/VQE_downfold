Step 1, Loss: -2.1684810860092663  gradient: 0.2959297737532497
Step 11, Loss: -2.1128964338359473  gradient: 2.7616396933927936
Step 21, Loss: -2.1558382943891887  gradient: 1.0758956078077646
Step 31, Loss: -2.1677307238490764  gradient: 0.4918761138613953
Step 41, Loss: -2.1742672753855943  gradient: 0.31410038514696187
Step 51, Loss: -2.1773991268463666  gradient: 0.20936452637095077
Step 61, Loss: -2.1793445356148555  gradient: 0.12704257442326483
Step 71, Loss: -2.1801780169439993  gradient: 0.07387376301538014
Step 81, Loss: -2.1805078170168746  gradient: 0.03651112528998423
Step 91, Loss: -2.1806253163324025  gradient: 0.022573005471343638
Step 101, Loss: -2.1806916462831856  gradient: 0.013824322285889099
Step 111, Loss: -2.1807547610128877  gradient: 0.009836885926861914
Step 121, Loss: -2.180826187010702  gradient: 0.009500382291079685
Step 131, Loss: -2.180924513931114  gradient: 0.008805134663866208
Step 141, Loss: -2.1810720785804985  gradient: 0.0098104394909019
Step 151, Loss: -2.181306924569521  gradient: 0.012873399227064054
Step 161, Loss: -2.1817004703988183  gradient: 0.01693858732234582
Step 171, Loss: -2.182383253662378  gradient: 0.02319037739245825
Step 181, Loss: -2.183571250383572  gradient: 0.031355627782739856
Step 191, Loss: -2.1855398902474272  gradient: 0.04086093250749339
Step 201, Loss: -2.1884686165111984  gradient: 0.047490162609157435
Step 211, Loss: -2.1921489364747324  gradient: 0.04761345484074108
Step 221, Loss: -2.195735590098498  gradient: 0.03980675421121191
Step 231, Loss: -2.1983496966229414  gradient: 0.028458577811139512
Step 241, Loss: -2.199904668270487  gradient: 0.020342498473611942
Step 251, Loss: -2.2007580762372365  gradient: 0.013320082317697334
Step 261, Loss: -2.2012100050824737  gradient: 0.008439140408033197
Step 271, Loss: -2.2014442552805207  gradient: 0.0056990621606376095
Step 281, Loss: -2.201566259261529  gradient: 0.004034049350183897
Step 291, Loss: -2.201629411798286  gradient: 0.0028166088672862545
Step 301, Loss: -2.201660652347537  gradient: 0.00193464571352221
Step 311, Loss: -2.2016753249809655  gradient: 0.001314543073743208
convergent at epoch 318; gradient 0.0009797499866781093 is below threshold